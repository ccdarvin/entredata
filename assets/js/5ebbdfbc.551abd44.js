"use strict";(self.webpackChunkdocsweb=self.webpackChunkdocsweb||[]).push([[634],{876:(e,a,n)=>{n.d(a,{Zo:()=>p,kt:()=>_});var s=n(2784);function t(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function r(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);a&&(s=s.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,s)}return n}function o(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?r(Object(n),!0).forEach((function(a){t(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function l(e,a){if(null==e)return{};var n,s,t=function(e,a){if(null==e)return{};var n,s,t={},r=Object.keys(e);for(s=0;s<r.length;s++)n=r[s],a.indexOf(n)>=0||(t[n]=e[n]);return t}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(s=0;s<r.length;s++)n=r[s],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(t[n]=e[n])}return t}var i=s.createContext({}),c=function(e){var a=s.useContext(i),n=a;return e&&(n="function"==typeof e?e(a):o(o({},a),e)),n},p=function(e){var a=c(e.components);return s.createElement(i.Provider,{value:a},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var a=e.children;return s.createElement(s.Fragment,{},a)}},m=s.forwardRef((function(e,a){var n=e.components,t=e.mdxType,r=e.originalType,i=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=c(n),m=t,_=u["".concat(i,".").concat(m)]||u[m]||d[m]||r;return n?s.createElement(_,o(o({ref:a},p),{},{components:n})):s.createElement(_,o({ref:a},p))}));function _(e,a){var n=arguments,t=a&&a.mdxType;if("string"==typeof e||t){var r=n.length,o=new Array(r);o[0]=m;var l={};for(var i in a)hasOwnProperty.call(a,i)&&(l[i]=a[i]);l.originalType=e,l[u]="string"==typeof e?e:t,o[1]=l;for(var c=2;c<r;c++)o[c]=n[c];return s.createElement.apply(null,o)}return s.createElement.apply(null,n)}m.displayName="MDXCreateElement"},472:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>i,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var s=n(7896),t=(n(2784),n(876));const r={title:"Implementaci\xf3n de Siamese Network",authors:["ccdarvin"]},o=void 0,l={permalink:"/article/2023/08/11/implementacion-de-siamese-network",source:"@site/blog/2023-08-11-implementacion-de-siamese-network.md",title:"Implementaci\xf3n de Siamese Network",description:"\xbfQue es una Siamese Network?",date:"2023-08-11T00:00:00.000Z",formattedDate:"11 de agosto de 2023",tags:[],readingTime:7.435,hasTruncateMarker:!1,authors:[{name:"Darvin Cotrina",title:"Creador de entredata.org",url:"https://github.com/ccdarvin",imageURL:"https://github.com/ccdarvin.png",key:"ccdarvin"}],frontMatter:{title:"Implementaci\xf3n de Siamese Network",authors:["ccdarvin"]},prevItem:{title:"Implementaci\xf3n de Siamese Network",permalink:"/article/implementacion-de-siamese-network"},nextItem:{title:"Modelo funcional usando el API de Keras",permalink:"/article/modelo-funcional-usando-el-API-de-Keras"}},i={authorsImageUrls:[void 0]},c=[{value:"\xbfQue es una Siamese Network?",id:"que-es-una-siamese-network",level:2},{value:"Importar modulos",id:"importar-modulos",level:2},{value:"Preparar los datos",id:"preparar-los-datos",level:2},{value:"Crear nuestros pares de datos positivos y negativos",id:"crear-nuestros-pares-de-datos-positivos-y-negativos",level:2},{value:"Modelo base",id:"modelo-base",level:2},{value:"Distancia Euclidiana",id:"distancia-euclidiana",level:3},{value:"Configurar modelo",id:"configurar-modelo",level:2},{value:"Entrenamos el modelo",id:"entrenamos-el-modelo",level:2},{value:"Evaluamos el modelo",id:"evaluamos-el-modelo",level:2},{value:"graficar funcion de perdida",id:"graficar-funcion-de-perdida",level:2}],p={toc:c},u="wrapper";function d(e){let{components:a,...r}=e;return(0,t.kt)(u,(0,s.Z)({},p,r,{components:a,mdxType:"MDXLayout"}),(0,t.kt)("h2",{id:"que-es-una-siamese-network"},"\xbfQue es una Siamese Network?"),(0,t.kt)("p",null,"Es un tipo especial de arquitecura de red neuronal que permite comparar\ndos imagenes y determinar si son similares o no, la caracteristica\nprincipal de este tipo de red es que comparten los mismos pesos y\narquitectura, es decir, son dos redes neuronales que comparten los\nmismos pesos y arquitectura, esto permite que la red pueda aprender a\ncomparar dos imagenes y determinar si son similares o no."),(0,t.kt)("h2",{id:"importar-modulos"},"Importar modulos"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n")),(0,t.kt)("h2",{id:"preparar-los-datos"},"Preparar los datos"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\n# cast to float32\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nprint('fashion_mnist train shape:', X_train.shape)\nprint('fashion_mnist test shape:', X_test.shape)\n\n# normalize data\nX_train /= 255.\nX_test /= 255.\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-text"},"fashion_mnist train shape: (60000, 28, 28)\nfashion_mnist test shape: (10000, 28, 28)\n")),(0,t.kt)("h2",{id:"crear-nuestros-pares-de-datos-positivos-y-negativos"},"Crear nuestros pares de datos positivos y negativos"),(0,t.kt)("ul",null,(0,t.kt)("li",{parentName:"ul"},(0,t.kt)("strong",{parentName:"li"},"Pares positivos"),": Dos im\xe1genes que contienen las mismas\ncaracteristicas"),(0,t.kt)("li",{parentName:"ul"},(0,t.kt)("strong",{parentName:"li"},"Pares negativos"),": Dos im\xe1genes que contienen diferentes\ncaracteristicas")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},'def create_pairs(X: np.ndarray, y: np.ndarray):\n    """\n    Args:\n        X (np.ndarray): Array de imagenes\n        y (np.ndarray): Array de etiquetas\n    return:\n        pairs (np.ndarray): Array de pares de imagenes\n        labels: Etiquetas de las imagenes, 1 si son pares positivos y 0 si son pares negativos\n    """\n    \n    # image indices by class labels: y\n    num_classes = max(y) + 1\n    indices = [np.where(y == i)[0] for i in range(num_classes)]\n    \n    pairs, labels = [], []\n    \n    # max number of pairs using the min number of images by class\n    n = min([len(i) for i in indices]) - 1\n    \n    for c in range(num_classes):\n        for i in range(n):\n            # positive pair\n            img1 = X[indices[c][i]]\n            # next image of the same class\n            img2 = X[indices[c][i+1]]\n            pairs.append((img1, img2))\n            labels.append(1.)\n            \n            # negative pair\n            # select a random class\n            neg = np.random.choice([_c for _c in range(num_classes) if _c != c])\n            # select a random image\n            img1 = X[indices[c][i]]\n            img2 = X[indices[neg][i]]\n            pairs.append((img1, img2))\n            labels.append(0.)\n            \n    return np.array(pairs), np.array(labels)\n \n')),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"X_train_pair, y_train_bin = create_pairs(X_train, y_train)\nX_test_pair, y_test_bin = create_pairs(X_test, y_test)\nprint(f'train pair: {X_train_pair.shape} and type {X_train_pair.dtype} label: {y_train_bin.shape} type {y_train_bin.dtype}')\nprint(f'test pair: {X_test_pair.shape} and type {X_test_pair.dtype} labe: {y_test_bin.shape} type {y_test_bin.dtype}')\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-text"},"train pair: (119980, 2, 28, 28) and type float32 label: (119980,) type float64\ntest pair: (19980, 2, 28, 28) and type float32 labe: (19980,) type float64\n")),(0,t.kt)("p",null,"Ya preparamos los pares de datos para entrenar la red neuronal ahora por\ncada ejemplo en nuestra input tenemos dos images y nuestro output es un\nvalor 0 o 1 dependiendo si son negativos o positivos respectivamente."),(0,t.kt)("p",null,"Para poder tener un contexto visual graficaremos las imagenes de\nejemplo, una a lado de la otra. En el c\xf3digo usamos un random para\nseleccionar el par de imagenes a mostrar esto se hace para que se pueda\njugar por los datos y ver distintos ejemplos."),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},'def plot_pair(pair: np.ndarray, label: float, pred: float = None):\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    ax[0].imshow(pair[0])\n    ax[1].imshow(pair[1])\n    if label:\n        title = "Positivo"\n    else:\n        title = "Negativo"\n        \n    if pred is not None:\n        if pred < 0.5:\n            title += f" - pred: {pred:.2f} - Positivo"\n        else:\n            title += f" - pred: {pred:.2f} - Negativo"\n    fig.suptitle(title)\n    plt.show()\n')),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"num_exam = random.randrange(len(X_train_pair))\nplot_pair(X_train_pair[num_exam], y_train_bin[num_exam])\n")),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(4779).Z,width:"822",height:"462"})),(0,t.kt)("h2",{id:"modelo-base"},"Modelo base"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},'input_shape = (28, 28, )\ndef build_model_base():\n    input = tf.keras.Input(shape=input_shape, name="base_input")\n    x = tf.keras.layers.Flatten(name="flatten_input")(input)\n    x = tf.keras.layers.Dense(128, activation=\'relu\', name="first_base_dense")(x)\n    x = tf.keras.layers.Dropout(0.1, name="first_dropout")(x)\n    x = tf.keras.layers.Dense(128, activation=\'relu\', name="second_base_dense")(x)\n    x = tf.keras.layers.Dropout(0.1, name="second_dropout")(x)\n    x = tf.keras.layers.Dense(128, activation=\'relu\', name="third_base_dense")(x)\n    \n    return tf.keras.Model(inputs=input, outputs=x, name="base_model")\n')),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"model_base = build_model_base()\ntf.keras.utils.plot_model(model_base, show_shapes=True)\n")),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(7850).Z,width:"367",height:"751"})),(0,t.kt)("p",null,"Vamos ahora a construir la Siamense Network, donde podremos ver que\ntenemos dos entradas que se enviaran a al modelo base y esta pasara por\nuna capa personalizada que calculara la distancia entre los dos vectores\nde salida de la red base, distancia euclidiana"),(0,t.kt)("h3",{id:"distancia-euclidiana"},"Distancia Euclidiana"),(0,t.kt)("p",null,"la distancia euclidiana es una medida de distancia entre dos puntos que\nse puede generalizar a cualquier dimensi\xf3n. En otras palabras, es la\ndistancia entre dos puntos que se puede medir con una regla. En dos\ndimensiones, la distancia euclidiana entre los puntos"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"def euclidean_distance(vects):\n    import keras.backend as K\n    vect_a, vect_b = vects\n    sum_square = K.sum(K.square(vect_a - vect_b), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n\ndef ouput_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0], 1)\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"# create input a\ninput_a = tf.keras.Input(shape=input_shape, name='left_input')\nvect_output_a = model_base(input_a)\n\n# create input b\ninput_b = tf.keras.Input(shape=input_shape, name='right_input')\nvect_output_b = model_base(input_b)\n\n# measure the similarity of the two vectorized outputs\noutput  = tf.keras.layers.Lambda(euclidean_distance, name='output_layer', output_shape=ouput_shape)([vect_output_a, vect_output_b])\n\n# create the model\nmodel = tf.keras.Model([input_a, input_b], output)\ntf.keras.utils.plot_model(model, show_shapes=True)\n")),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(403).Z,width:"669",height:"301"})),(0,t.kt)("h2",{id:"configurar-modelo"},"Configurar modelo"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"\ndef contrastive_loss_with_margin(margin):\n    def contrastive_loss(y_true, y_pred):\n        '''Contrastive loss from Hadsell-et-al.'06\n        http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n        '''\n        import tensorflow.keras.backend as K\n        square_pred = K.square(y_pred)\n        margin_square = K.square(K.maximum(margin - y_pred, 0))\n        return (y_true * square_pred + (1 - y_true) * margin_square)\n    return contrastive_loss\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"rms = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\nmodel.compile(optimizer=rms, loss=contrastive_loss_with_margin(1), metrics=['accuracy'])\n")),(0,t.kt)("h2",{id:"entrenamos-el-modelo"},"Entrenamos el modelo"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"history = model.fit([X_train_pair[:, 0], X_train_pair[:, 1]], y_train_bin, epochs=30, batch_size=180, validation_data=([X_test_pair[:, 0], X_test_pair[:, 1]], y_test_bin))\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-text"},"Epoch 1/30\n667/667 [==============================] - 6s 7ms/step - loss: 0.1847 - accuracy: 0.2415 - val_loss: 0.1192 - val_accuracy: 0.1572\nEpoch 2/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.1169 - accuracy: 0.1469 - val_loss: 0.1023 - val_accuracy: 0.1336\nEpoch 3/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.1039 - accuracy: 0.1306 - val_loss: 0.0955 - val_accuracy: 0.1266\nEpoch 4/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0968 - accuracy: 0.1215 - val_loss: 0.0910 - val_accuracy: 0.1217\nEpoch 5/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0920 - accuracy: 0.1152 - val_loss: 0.0883 - val_accuracy: 0.1200\nEpoch 6/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0880 - accuracy: 0.1096 - val_loss: 0.0851 - val_accuracy: 0.1137\nEpoch 7/30\n667/667 [==============================] - 4s 5ms/step - loss: 0.0846 - accuracy: 0.1046 - val_loss: 0.0825 - val_accuracy: 0.1064\nEpoch 8/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0818 - accuracy: 0.1006 - val_loss: 0.0804 - val_accuracy: 0.1040\nEpoch 9/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0794 - accuracy: 0.0970 - val_loss: 0.0786 - val_accuracy: 0.1025\nEpoch 10/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0771 - accuracy: 0.0931 - val_loss: 0.0777 - val_accuracy: 0.0988\nEpoch 11/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0750 - accuracy: 0.0906 - val_loss: 0.0757 - val_accuracy: 0.0969\nEpoch 12/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0733 - accuracy: 0.0877 - val_loss: 0.0746 - val_accuracy: 0.0946\nEpoch 13/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0716 - accuracy: 0.0852 - val_loss: 0.0739 - val_accuracy: 0.0930\nEpoch 14/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0699 - accuracy: 0.0832 - val_loss: 0.0721 - val_accuracy: 0.0910\nEpoch 15/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0684 - accuracy: 0.0813 - val_loss: 0.0720 - val_accuracy: 0.0911\nEpoch 16/30\n667/667 [==============================] - 4s 5ms/step - loss: 0.0671 - accuracy: 0.0798 - val_loss: 0.0705 - val_accuracy: 0.0858\nEpoch 17/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0661 - accuracy: 0.0779 - val_loss: 0.0704 - val_accuracy: 0.0880\nEpoch 18/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0648 - accuracy: 0.0764 - val_loss: 0.0699 - val_accuracy: 0.0890\nEpoch 19/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0637 - accuracy: 0.0752 - val_loss: 0.0693 - val_accuracy: 0.0877\nEpoch 20/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0626 - accuracy: 0.0729 - val_loss: 0.0683 - val_accuracy: 0.0863\nEpoch 21/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0616 - accuracy: 0.0724 - val_loss: 0.0683 - val_accuracy: 0.0880\nEpoch 22/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0608 - accuracy: 0.0718 - val_loss: 0.0671 - val_accuracy: 0.0845\nEpoch 23/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0599 - accuracy: 0.0700 - val_loss: 0.0671 - val_accuracy: 0.0852\nEpoch 24/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0591 - accuracy: 0.0698 - val_loss: 0.0670 - val_accuracy: 0.0849\nEpoch 25/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0585 - accuracy: 0.0693 - val_loss: 0.0663 - val_accuracy: 0.0843\nEpoch 26/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0578 - accuracy: 0.0683 - val_loss: 0.0660 - val_accuracy: 0.0848\nEpoch 27/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0568 - accuracy: 0.0671 - val_loss: 0.0659 - val_accuracy: 0.0848\nEpoch 28/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0563 - accuracy: 0.0671 - val_loss: 0.0658 - val_accuracy: 0.0852\nEpoch 29/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0559 - accuracy: 0.0663 - val_loss: 0.0650 - val_accuracy: 0.0834\nEpoch 30/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0553 - accuracy: 0.0663 - val_loss: 0.0655 - val_accuracy: 0.0842\n")),(0,t.kt)("h2",{id:"evaluamos-el-modelo"},"Evaluamos el modelo"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"pred = model.predict([X_test_pair[:, 0], X_test_pair[:, 1]])\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-text"},"625/625 [==============================] - 1s 2ms/step\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"examples = np.random.choice(range(len(pred)), size=5, replace=False)\n\nfor i in examples:\n    plot_pair(X_test_pair[i], y_test_bin[i], pred[i][0])\n")),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(7684).Z,width:"822",height:"462"})),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(9316).Z,width:"822",height:"462"})),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(2975).Z,width:"822",height:"462"})),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(6444).Z,width:"822",height:"462"})),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(4433).Z,width:"822",height:"462"})),(0,t.kt)("h2",{id:"graficar-funcion-de-perdida"},"graficar funcion de perdida"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Modelo de perdida')\nplt.ylabel('Perdida')\nplt.show()\n")),(0,t.kt)("p",null,(0,t.kt)("img",{src:n(305).Z,width:"577",height:"435"})))}d.isMDXComponent=!0},403:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-11-output-1-72334abd488d3f05c37ddbd71fb63a33.png"},7684:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-16-output-1-55afe6e237a3e7a9799f6dab1188bd05.png"},9316:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-16-output-2-714dd2ee98b763857283e81598709141.png"},2975:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-16-output-3-f65280906dd9fc0b65e21e609e853bbe.png"},6444:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-16-output-4-6417be9758c6ec2163ef111bea6fd665.png"},4433:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-16-output-5-c2ff5e9e6864f2befc4f39b43f78d70f.png"},305:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-17-output-1-975acb257d7dff2cdfcedfd4323ca706.png"},4779:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-7-output-1-33bdc53ef5292206b1311132827fcc75.png"},7850:(e,a,n)=>{n.d(a,{Z:()=>s});const s=n.p+"assets/images/cell-9-output-1-8d4a2007f356c6fa4acafdbfb6e72c1e.png"}}]);