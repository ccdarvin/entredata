"use strict";(self.webpackChunkdocsweb=self.webpackChunkdocsweb||[]).push([[7961],{876:(e,a,n)=>{n.d(a,{Zo:()=>c,kt:()=>_});var t=n(2784);function s(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function r(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function o(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?r(Object(n),!0).forEach((function(a){s(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function i(e,a){if(null==e)return{};var n,t,s=function(e,a){if(null==e)return{};var n,t,s={},r=Object.keys(e);for(t=0;t<r.length;t++)n=r[t],a.indexOf(n)>=0||(s[n]=e[n]);return s}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)n=r[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(s[n]=e[n])}return s}var l=t.createContext({}),p=function(e){var a=t.useContext(l),n=a;return e&&(n="function"==typeof e?e(a):o(o({},a),e)),n},c=function(e){var a=p(e.components);return t.createElement(l.Provider,{value:a},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},m=t.forwardRef((function(e,a){var n=e.components,s=e.mdxType,r=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),u=p(n),m=s,_=u["".concat(l,".").concat(m)]||u[m]||d[m]||r;return n?t.createElement(_,o(o({ref:a},c),{},{components:n})):t.createElement(_,o({ref:a},c))}));function _(e,a){var n=arguments,s=a&&a.mdxType;if("string"==typeof e||s){var r=n.length,o=new Array(r);o[0]=m;var i={};for(var l in a)hasOwnProperty.call(a,l)&&(i[l]=a[l]);i.originalType=e,i[u]="string"==typeof e?e:s,o[1]=i;for(var p=2;p<r;p++)o[p]=n[p];return t.createElement.apply(null,o)}return t.createElement.apply(null,n)}m.displayName="MDXCreateElement"},7820:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>p});var t=n(7896),s=(n(2784),n(876));const r={title:"Implementaci\xf3n de Siamese Network",authors:["ccdarvin"]},o=void 0,i={permalink:"/en/article/implementacion-de-siamese-network",source:"@site/blog/implementacion-de-siamese-network.md",title:"Implementaci\xf3n de Siamese Network",description:"\xbfQue es una Siamese Network?",date:"2023-08-12T23:45:55.765Z",formattedDate:"August 12, 2023",tags:[],readingTime:6.48,hasTruncateMarker:!1,authors:[{name:"Darvin Cotrina",title:"Creador de entredata.org",url:"https://github.com/ccdarvin",imageURL:"https://github.com/ccdarvin.png",key:"ccdarvin"}],frontMatter:{title:"Implementaci\xf3n de Siamese Network",authors:["ccdarvin"]},nextItem:{title:"Implementaci\xf3n de Siamese Network",permalink:"/en/article/2023/08/11/implementacion-de-siamese-network"}},l={authorsImageUrls:[void 0]},p=[{value:"\xbfQue es una Siamese Network?",id:"que-es-una-siamese-network",level:2},{value:"Importar modulos",id:"importar-modulos",level:2},{value:"Preparar los datos",id:"preparar-los-datos",level:2},{value:"Crear nuestros pares de datos positivos y negativos",id:"crear-nuestros-pares-de-datos-positivos-y-negativos",level:2},{value:"Modelo base",id:"modelo-base",level:2},{value:"Distancia Euclidiana",id:"distancia-euclidiana",level:3},{value:"Configurar modelo",id:"configurar-modelo",level:2},{value:"Entrenamos el modelo",id:"entrenamos-el-modelo",level:2},{value:"Evaluamos el modelo",id:"evaluamos-el-modelo",level:2},{value:"graficar funcion de perdida",id:"graficar-funcion-de-perdida",level:2}],c={toc:p},u="wrapper";function d(e){let{components:a,...r}=e;return(0,s.kt)(u,(0,t.Z)({},c,r,{components:a,mdxType:"MDXLayout"}),(0,s.kt)("h2",{id:"que-es-una-siamese-network"},"\xbfQue es una Siamese Network?"),(0,s.kt)("p",null,"Es un tipo especial de arquitecura de red neuronal que permite comparar\ndos imagenes y determinar si son similares o no, la caracteristica\nprincipal de este tipo de red es que comparten los mismos pesos y\narquitectura, es decir, son dos redes neuronales que comparten los\nmismos pesos y arquitectura, esto permite que la red pueda aprender a\ncomparar dos imagenes y determinar si son similares o no."),(0,s.kt)("h2",{id:"importar-modulos"},"Importar modulos"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n")),(0,s.kt)("h2",{id:"preparar-los-datos"},"Preparar los datos"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\n# cast to float32\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nprint('fashion_mnist train shape:', X_train.shape)\nprint('fashion_mnist test shape:', X_test.shape)\n\n# normalize data\nX_train /= 255.\nX_test /= 255.\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-text"},"fashion_mnist train shape: (60000, 28, 28)\nfashion_mnist test shape: (10000, 28, 28)\n")),(0,s.kt)("h2",{id:"crear-nuestros-pares-de-datos-positivos-y-negativos"},"Crear nuestros pares de datos positivos y negativos"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Pares positivos"),": Dos im\xe1genes que contienen las mismas\ncaracteristicas"),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Pares negativos"),": Dos im\xe1genes que contienen diferentes\ncaracteristicas")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'def create_pairs(X: np.ndarray, y: np.ndarray):\n    """\n    Args:\n        X (np.ndarray): Array de imagenes\n        y (np.ndarray): Array de etiquetas\n    return:\n        pairs (np.ndarray): Array de pares de imagenes\n        labels: Etiquetas de las imagenes, 1 si son pares positivos y 0 si son pares negativos\n    """\n    \n    # image indices by class labels: y\n    num_classes = max(y) + 1\n    indices = [np.where(y == i)[0] for i in range(num_classes)]\n    \n    pairs, labels = [], []\n    \n    # max number of pairs using the min number of images by class\n    n = min([len(i) for i in indices]) - 1\n    \n    for c in range(num_classes):\n        for i in range(n):\n            # positive pair\n            img1 = X[indices[c][i]]\n            # next image of the same class\n            img2 = X[indices[c][i+1]]\n            pairs.append((img1, img2))\n            labels.append(1.)\n            \n            # negative pair\n            # select a random class\n            neg = np.random.choice([_c for _c in range(num_classes) if _c != c])\n            # select a random image\n            img1 = X[indices[c][i]]\n            img2 = X[indices[neg][i]]\n            pairs.append((img1, img2))\n            labels.append(0.)\n            \n    return np.array(pairs), np.array(labels)\n \n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"X_train_pair, y_train_bin = create_pairs(X_train, y_train)\nX_test_pair, y_test_bin = create_pairs(X_test, y_test)\nprint(f'train pair: {X_train_pair.shape} and type {X_train_pair.dtype} label: {y_train_bin.shape} type {y_train_bin.dtype}')\nprint(f'test pair: {X_test_pair.shape} and type {X_test_pair.dtype} labe: {y_test_bin.shape} type {y_test_bin.dtype}')\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-text"},"train pair: (119980, 2, 28, 28) and type float32 label: (119980,) type float64\ntest pair: (19980, 2, 28, 28) and type float32 labe: (19980,) type float64\n")),(0,s.kt)("p",null,"Ya preparamos los pares de datos para entrenar la red neuronal ahora por\ncada ejemplo en nuestra input tenemos dos images y nuestro output es un\nvalor 0 o 1 dependiendo si son negativos o positivos respectivamente."),(0,s.kt)("p",null,"Para poder tener un contexto visual graficaremos las imagenes de\nejemplo, una a lado de la otra. En el c\xf3digo usamos un random para\nseleccionar el par de imagenes a mostrar esto se hace para que se pueda\njugar por los datos y ver distintos ejemplos."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'def plot_pair(pair: np.ndarray, label: float, pred: float = None):\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    ax[0].imshow(pair[0])\n    ax[1].imshow(pair[1])\n    if label:\n        title = "Positivo"\n    else:\n        title = "Negativo"\n        \n    if pred is not None:\n        if pred < 0.5:\n            title += f" - pred: {pred:.2f} - Positivo"\n        else:\n            title += f" - pred: {pred:.2f} - Negativo"\n    fig.suptitle(title)\n    plt.show()\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"num_exam = random.randrange(len(X_train_pair))\nplot_pair(X_train_pair[num_exam], y_train_bin[num_exam])\n")),(0,s.kt)("p",null,(0,s.kt)("img",{src:n(6496).Z,width:"822",height:"462"})),(0,s.kt)("h2",{id:"modelo-base"},"Modelo base"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'input_shape = (28, 28, )\ndef build_model_base():\n    input = tf.keras.Input(shape=input_shape, name="base_input")\n    x = tf.keras.layers.Flatten(name="flatten_input")(input)\n    x = tf.keras.layers.Dense(128, activation=\'relu\', name="first_base_dense")(x)\n    x = tf.keras.layers.Dropout(0.1, name="first_dropout")(x)\n    x = tf.keras.layers.Dense(128, activation=\'relu\', name="second_base_dense")(x)\n    x = tf.keras.layers.Dropout(0.1, name="second_dropout")(x)\n    x = tf.keras.layers.Dense(128, activation=\'relu\', name="third_base_dense")(x)\n    \n    return tf.keras.Model(inputs=input, outputs=x, name="base_model")\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"model_base = build_model_base()\ntf.keras.utils.plot_model(model_base, show_shapes=True)\n")),(0,s.kt)("p",null,(0,s.kt)("img",{src:n(326).Z,width:"367",height:"751"})),(0,s.kt)("p",null,"Vamos ahora a construir la Siamense Network, donde podremos ver que\ntenemos dos entradas que se enviaran a al modelo base y esta pasara por\nuna capa personalizada que calculara la distancia entre los dos vectores\nde salida de la red base, distancia euclidiana"),(0,s.kt)("h3",{id:"distancia-euclidiana"},"Distancia Euclidiana"),(0,s.kt)("p",null,"la distancia euclidiana es una medida de distancia entre dos puntos que\nse puede generalizar a cualquier dimensi\xf3n. En otras palabras, es la\ndistancia entre dos puntos que se puede medir con una regla. En dos\ndimensiones, la distancia euclidiana entre los puntos"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"def euclidean_distance(vects):\n    import keras.backend as K\n    vect_a, vect_b = vects\n    sum_square = K.sum(K.square(vect_a - vect_b), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n\ndef ouput_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0], 1)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"# create input a\ninput_a = tf.keras.Input(shape=input_shape, name='left_input')\nvect_output_a = model_base(input_a)\n\n# create input b\ninput_b = tf.keras.Input(shape=input_shape, name='right_input')\nvect_output_b = model_base(input_b)\n\n# measure the similarity of the two vectorized outputs\noutput  = tf.keras.layers.Lambda(euclidean_distance, name='output_layer', output_shape=ouput_shape)([vect_output_a, vect_output_b])\n\n# create the model\nmodel = tf.keras.Model([input_a, input_b], output)\ntf.keras.utils.plot_model(model, show_shapes=True)\n")),(0,s.kt)("p",null,(0,s.kt)("img",{src:n(1310).Z,width:"669",height:"301"})),(0,s.kt)("h2",{id:"configurar-modelo"},"Configurar modelo"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"\ndef contrastive_loss_with_margin(margin):\n    def contrastive_loss(y_true, y_pred):\n        '''Contrastive loss from Hadsell-et-al.'06\n        http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n        '''\n        import tensorflow.keras.backend as K\n        square_pred = K.square(y_pred)\n        margin_square = K.square(K.maximum(margin - y_pred, 0))\n        return (y_true * square_pred + (1 - y_true) * margin_square)\n    return contrastive_loss\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"rms = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\nmodel.compile(optimizer=rms, loss=contrastive_loss_with_margin(1), metrics=['accuracy'])\n")),(0,s.kt)("h2",{id:"entrenamos-el-modelo"},"Entrenamos el modelo"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"history = model.fit([X_train_pair[:, 0], X_train_pair[:, 1]], y_train_bin, epochs=30, batch_size=180, validation_data=([X_test_pair[:, 0], X_test_pair[:, 1]], y_test_bin))\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-text"},"Epoch 1/30\n667/667 [==============================] - 5s 6ms/step - loss: 0.1791 - accuracy: 0.2385 - val_loss: 0.1182 - val_accuracy: 0.1557\nEpoch 2/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.1184 - accuracy: 0.1506 - val_loss: 0.1027 - val_accuracy: 0.1378\nEpoch 3/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.1055 - accuracy: 0.1330 - val_loss: 0.0954 - val_accuracy: 0.1259\nEpoch 4/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0977 - accuracy: 0.1214 - val_loss: 0.0912 - val_accuracy: 0.1204\nEpoch 5/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.0921 - accuracy: 0.1134 - val_loss: 0.0873 - val_accuracy: 0.1146\nEpoch 6/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0883 - accuracy: 0.1082 - val_loss: 0.0841 - val_accuracy: 0.1092\nEpoch 7/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.0848 - accuracy: 0.1036 - val_loss: 0.0817 - val_accuracy: 0.1066\nEpoch 8/30\n667/667 [==============================] - 5s 8ms/step - loss: 0.0821 - accuracy: 0.0995 - val_loss: 0.0793 - val_accuracy: 0.1033\nEpoch 9/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.0794 - accuracy: 0.0963 - val_loss: 0.0782 - val_accuracy: 0.1010\nEpoch 10/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.0772 - accuracy: 0.0932 - val_loss: 0.0766 - val_accuracy: 0.0982\nEpoch 11/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.0752 - accuracy: 0.0902 - val_loss: 0.0749 - val_accuracy: 0.0960\nEpoch 12/30\n667/667 [==============================] - 5s 8ms/step - loss: 0.0732 - accuracy: 0.0877 - val_loss: 0.0735 - val_accuracy: 0.0943\nEpoch 13/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.0715 - accuracy: 0.0851 - val_loss: 0.0720 - val_accuracy: 0.0906\nEpoch 14/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0701 - accuracy: 0.0827 - val_loss: 0.0712 - val_accuracy: 0.0891\nEpoch 15/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.0685 - accuracy: 0.0803 - val_loss: 0.0704 - val_accuracy: 0.0887\nEpoch 16/30\n667/667 [==============================] - 5s 7ms/step - loss: 0.0672 - accuracy: 0.0790 - val_loss: 0.0698 - val_accuracy: 0.0886\nEpoch 17/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0659 - accuracy: 0.0771 - val_loss: 0.0691 - val_accuracy: 0.0873\nEpoch 18/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0649 - accuracy: 0.0764 - val_loss: 0.0688 - val_accuracy: 0.0864\nEpoch 19/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0638 - accuracy: 0.0751 - val_loss: 0.0676 - val_accuracy: 0.0846\nEpoch 20/30\n667/667 [==============================] - 4s 6ms/step - loss: 0.0626 - accuracy: 0.0738 - val_loss: 0.0673 - val_accuracy: 0.0853\nEpoch 21/30\n610/667 [==========================>...] - ETA: 0s - loss: 0.0617 - accuracy: 0.0731\n")),(0,s.kt)("h2",{id:"evaluamos-el-modelo"},"Evaluamos el modelo"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"pred = model.predict([X_test_pair[:, 0], X_test_pair[:, 1]])\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"examples = np.random.choice(range(len(pred)), size=5, replace=False)\n\nfor i in examples:\n    plot_pair(X_test_pair[i], y_test_bin[i], pred[i][0])\n")),(0,s.kt)("h2",{id:"graficar-funcion-de-perdida"},"graficar funcion de perdida"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Modelo de perdida')\nplt.ylabel('Perdida')\nplt.show()\n")))}d.isMDXComponent=!0},1310:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/cell-11-output-1-72334abd488d3f05c37ddbd71fb63a33.png"},6496:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/cell-7-output-1-4ec917e7a7ebc28ac95fac941fe6c187.png"},326:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/cell-9-output-1-8d4a2007f356c6fa4acafdbfb6e72c1e.png"}}]);